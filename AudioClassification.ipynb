{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo3mMqCxmlLX"
      },
      "outputs": [],
      "source": [
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2SX-CNyLAyv"
      },
      "outputs": [],
      "source": [
        "dataset, label =  [], []\n",
        "n = 1\n",
        "l = 0\n",
        "c = 0\n",
        "for filename in os.listdir('/content/drive/MyDrive/namakav_waves'):\n",
        "  audio = '/content/drive/MyDrive/namakav_waves/'+filename\n",
        "  fs, data = wavfile.read(audio)\n",
        "  b = 0\n",
        "  duration = int(data.shape[0]/int(n*fs))\n",
        "  for i in range (duration):\n",
        "    left_CH = data[b:b+int(n*fs),0]\n",
        "    right_CH = data[b:b+int(n*fs),1]\n",
        "    L_CH = left_CH.reshape(left_CH.shape[0],1)\n",
        "    dataset.append(L_CH)\n",
        "    label.append(0)\n",
        "    R_CH = right_CH.reshape(right_CH.shape[0],1)\n",
        "    dataset.append(R_CH)\n",
        "    label.append(1)\n",
        "    b = b+int(n*fs)\n",
        "  l = l + data.shape[0]/int(n*fs)\n",
        "  c = c+1\n",
        "\n",
        "print(\"number of wav files is : \",str(c))\n",
        "print(\"sampling frequency of wav files is : \",str(fs),\" hz\")\n",
        "print(\"average length of wav files is : \",str(l/c/60),\" minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFjl9hen_mrh"
      },
      "outputs": [],
      "source": [
        "# Tensorflow / Keras\n",
        "import tensorflow as tf # used to access argmax function\n",
        "from tensorflow import keras # for building Neural Networks\n",
        "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
        "from keras import Input # for instantiating a keras tensor\n",
        "from keras.layers import Dense, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Dropout # for adding Concolutional and densely-connected NN layers.\n",
        "from keras import layers\n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd # for data manipulation\n",
        "import numpy as np # for data manipulation\n",
        "\n",
        "# Sklearn\n",
        "import sklearn # for model evaluation\n",
        "from sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n",
        "from sklearn.metrics import classification_report # for model evaluation metrics\n",
        "from sklearn.preprocessing import OrdinalEncoder # for encoding labels\n",
        "\n",
        "# Visualization\n",
        "import cv2 # for ingesting images\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt # for showing images\n",
        "\n",
        "# Other utilities\n",
        "import sys\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo3LWxhMI-4d"
      },
      "outputs": [],
      "source": [
        "# Convert audio data to numpy array\n",
        "dataset = np.array(dataset, dtype=\"float\")\n",
        "\n",
        "# Show data shape\n",
        "print(\"Shape of whole data: \", dataset.shape)\n",
        "\n",
        "# Convert Labels list to numpy array\n",
        "label=np.array(label)\n",
        "\n",
        "# Encode labels\n",
        "enc = OrdinalEncoder()\n",
        "y=enc.fit_transform(label.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzKNyr4VQZ8V"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QALp988v34cM"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---- Create training and testing samples ---\n",
        "train_ratio = 0.75\n",
        "validation_ratio = 0.20\n",
        "test_ratio = 0.05\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset, y, test_size=1-train_ratio, random_state=0)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio+validation_ratio), random_state=0)\n",
        "y_train=y_train.reshape(-1,1)\n",
        "y_test=y_test.reshape(-1,1)\n",
        "\n",
        "# Print shapes\n",
        "# Note, model input must have a four-dimensional shape [samples, rows, columns, channels]\n",
        "print(\"Shape of X_train: \", X_train.shape)\n",
        "print(\"Shape of y_train: \", y_train.shape)\n",
        "print(\"Shape of X_test: \", X_test.shape)\n",
        "print(\"Shape of y_test: \", y_test.shape)\n",
        "print(\"Shape of X_val: \", X_val.shape)\n",
        "print(\"Shape of y_val: \", y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first model without batch normalization\n",
        "model_1 = Sequential()\n",
        "model_1.add(Conv1D(8, 3, activation='relu', input_shape=(int(n*fs),1)))\n",
        "model_1.add(Conv1D(16, 3, activation='relu'))\n",
        "model_1.add(MaxPooling1D())\n",
        "\n",
        "\n",
        "model_1.add(Conv1D(32, 3, activation='relu'))\n",
        "model_1.add(Conv1D(64, 3, activation='relu'))\n",
        "model_1.add(MaxPooling1D())\n",
        "\n",
        "model_1.add(Conv1D(128, 3, activation='relu'))\n",
        "model_1.add(Conv1D(64, 3, activation='relu'))\n",
        "model_1.add(MaxPooling1D())\n",
        "\n",
        "model_1.add(Conv1D(128, 3, activation='relu'))\n",
        "\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "model_1.compile(loss=tf.losses.BinaryCrossentropy(),optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "model_1.summary()\n",
        "\n",
        "hist_1 = model_1.fit(X_train, y_train, epochs=7, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "iROMLOO2Xmse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample model with more layers and without batch normalization\n",
        "model_2 = Sequential()\n",
        "model_2.add(Conv1D(8, 3, activation='relu', input_shape=(int(n*fs),1)))\n",
        "model_2.add(Conv1D(16, 3, activation='relu'))\n",
        "model_2.add(MaxPooling1D())\n",
        "\n",
        "\n",
        "model_2.add(Conv1D(32, 3, activation='relu'))\n",
        "model_2.add(Conv1D(64, 3, activation='relu'))\n",
        "model_2.add(MaxPooling1D())\n",
        "\n",
        "model_2.add(Conv1D(128, 3, activation='relu'))\n",
        "model_2.add(Conv1D(64, 3, activation='relu'))\n",
        "model_2.add(MaxPooling1D())\n",
        "\n",
        "model_2.add(Conv1D(128, 3, activation='relu'))\n",
        "\n",
        "model_2.add(Conv1D(128, 3, activation='relu'))\n",
        "model_2.add(Conv1D(64, 3, activation='relu'))\n",
        "model_2.add(MaxPooling1D())\n",
        "\n",
        "model_2.add(Conv1D(128, 3, activation='relu'))\n",
        "\n",
        "\n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "model_2.compile(loss=tf.losses.BinaryCrossentropy(),optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "model_2.summary()\n",
        "\n",
        "hist_2 = model_2.fit(X_train, y_train, epochs=7, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "A71QeFbEXw_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enVIguE5huo_"
      },
      "outputs": [],
      "source": [
        "model_3 = Sequential()\n",
        "model_3.add(Conv1D(8, 3, activation='relu', input_shape=(int(n*fs),1)))\n",
        "\n",
        "model_3.add(BatchNormalization())\n",
        "model_3.add(Conv1D(16, 3, activation='relu'))\n",
        "model_3.add(MaxPooling1D())\n",
        "\n",
        "\n",
        "model_3.add(Conv1D(32, 3, activation='relu'))\n",
        "model_3.add(Conv1D(64, 3, activation='relu'))\n",
        "model_3.add(MaxPooling1D())\n",
        "\n",
        "\n",
        "model_3.add(Conv1D(128, 3, activation='relu'))\n",
        "model_3.add(Conv1D(64, 3, activation='relu'))\n",
        "model_3.add(MaxPooling1D())\n",
        "\n",
        "\n",
        "model_3.add(Conv1D(128, 3, activation='relu'))\n",
        "\n",
        "model_3.add(Flatten())\n",
        "\n",
        "model_3.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "model_3.compile(loss=tf.losses.BinaryCrossentropy(),optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "model_3.summary()\n",
        "\n",
        "\n",
        "hist_3 = model_3.fit(X_train, y_train, batch_size=32, epochs=7, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ror4QrzUHIgw"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,4))\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(hist_1.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist_1.history['val_loss'], color='orange', label='val_loss')\n",
        "plt.title('Loss model1', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(hist_2.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist_2.history['val_loss'], color='orange', label='val_loss')\n",
        "plt.title('Loss model2', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(hist_3.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist_3.history['val_loss'], color='orange', label='val_loss')\n",
        "plt.title('Loss model3', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(30,4))\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(hist_1.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist_1.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "plt.title('Accuracy model1', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(hist_2.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist_2.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "plt.title('Accuracy model2', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(hist_3.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist_3.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "plt.title('Accuracy model3', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOf_bIGCM58S"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
        "\n",
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = BinaryAccuracy()\n",
        "\n",
        "yhat = model_1.predict(X_test)\n",
        "pre.update_state(y_test, yhat)\n",
        "re.update_state(y_test, yhat)\n",
        "acc.update_state(y_test, yhat)\n",
        "\n",
        "print(\"Test Part for model1\")\n",
        "print(\"Precision: \",pre.result().numpy(),\"    \", \"Recall: \", re.result().numpy(),\"    \", \"Accuracy: \",acc.result().numpy())\n",
        "\n",
        "\n",
        "yhat = model_2.predict(X_test)\n",
        "pre.update_state(y_test, yhat)\n",
        "re.update_state(y_test, yhat)\n",
        "acc.update_state(y_test, yhat)\n",
        "\n",
        "print(\"Test Part for model2\")\n",
        "print(\"Precision: \",pre.result().numpy(),\"    \", \"Recall: \", re.result().numpy(),\"    \", \"Accuracy: \",acc.result().numpy())\n",
        "\n",
        "\n",
        "yhat = model_3.predict(X_test)\n",
        "pre.update_state(y_test, yhat)\n",
        "re.update_state(y_test, yhat)\n",
        "acc.update_state(y_test, yhat)\n",
        "\n",
        "\n",
        "print(\"Test Part for model3\")\n",
        "print(\"Precision: \",pre.result().numpy(),\"    \", \"Recall: \", re.result().numpy(),\"    \", \"Accuracy: \",acc.result().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QpmBza9Qc-0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def predictQualityofAudio(model,audio_dir,target):\n",
        "    dataset = []\n",
        "    fs, data = wavfile.read('/content/drive/MyDrive/'+audio_dir)\n",
        "    n=1\n",
        "    counter=0\n",
        "    b = 0\n",
        "    duration = int(data.shape[0]/int(n*fs))\n",
        "    for i in range (duration):\n",
        "      sample = data[b:b+int(n*fs)]\n",
        "      sample = sample.reshape(sample.shape[0],1)\n",
        "      dataset.append(sample)\n",
        "      b = b+int(n*fs)\n",
        "      counter+=1\n",
        "\n",
        "    dataset = np.array(dataset, dtype=\"float\")\n",
        "    yhat = model.predict(dataset)\n",
        "    if target==0:\n",
        "      score = len(yhat[yhat<=0.5])\n",
        "      print(\"The quality of predict is \"+str(score)+\" out of \"+str(counter)+\" for a valid sound \"+audio_dir+\".\")\n",
        "    elif target==1:\n",
        "      score = len(yhat[yhat>=0.5])\n",
        "      print(\"The quality of predict is \"+str(score)+\" out of \"+str(counter)+ \" for a damaged sound \"+audio_dir+\".\")\n",
        "\n",
        "print(\"model_1:\")\n",
        "predictQualityofAudio(model_1,\"RMPABOL0.wav\",0)\n",
        "predictQualityofAudio(model_1,\"RMPABOL1.wav\",1)\n",
        "predictQualityofAudio(model_1,\"RMPBARZ0.wav\",0)\n",
        "predictQualityofAudio(model_1,\"RMPBARZ1.wav\",1)\n",
        "\n",
        "print(\"model_2:\")\n",
        "predictQualityofAudio(model_2,\"RMPABOL0.wav\",0)\n",
        "predictQualityofAudio(model_2,\"RMPABOL1.wav\",1)\n",
        "predictQualityofAudio(model_2,\"RMPBARZ0.wav\",0)\n",
        "predictQualityofAudio(model_2,\"RMPBARZ1.wav\",1)\n",
        "\n",
        "\n",
        "print(\"model_3:\")\n",
        "predictQualityofAudio(model_3,\"RMPBARZ0.wav\",0)\n",
        "predictQualityofAudio(model_3,\"RMPBARZ1.wav\",1)\n",
        "predictQualityofAudio(model_3,\"RMPABOL0.wav\",0)\n",
        "predictQualityofAudio(model_3,\"RMPABOL1.wav\",1)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}